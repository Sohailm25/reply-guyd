# Polychromic LoRA - Phase 1 (SFT Warm-start with Diversity)
#
# This config trains a polychromic LoRA model on Phase 1 data (50% of full dataset)
# to create a diversity-aware warm-start checkpoint for subsequent GRPO training.
#
# Scientific rationale:
# - Shorter training (2 epochs vs 3) since Phase 2 continues from this checkpoint
# - Uses half the data (non-overlapping with Phase 2)
# - Establishes diverse generation capability before GRPO refinement
# - Hypothesis: Diverse warm-start improves GRPO exploration
#
# Usage:
#   python scripts/training/train_model.py \
#     --config config/experiments/polychromic_warmstart.yaml

_base_: ../lora_config.yaml

# Experiment metadata
experiment:
  name: "polychromic_warmstart"
  phase: 1
  description: "Polychromic LoRA warm-start for GRPO Phase 2"
  purpose: "Establish diverse generation baseline, prepare for GRPO refinement"

# Model (inherits from base)
model:
  # Same as base config

# LoRA (inherits from base)
lora:
  # Same as base config

# Training - adjusted for warm-start + polychromic
training:
  # Shorter training since we continue in Phase 2
  num_epochs: 2  # vs 3 for full training
  
  # Standard hyperparameters (same as baseline for fair comparison)
  learning_rate: 2.0e-4
  warmup_ratio: 0.03
  weight_decay: 0.01
  max_grad_norm: 1.0
  
  # Batch sizes (effective batch size = 16)
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 4
  
  # Optimizer
  optim: "adamw_torch"
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  
  # Learning rate scheduler
  lr_scheduler_type: "cosine"
  
  # Mixed precision
  bf16: true
  fp16: false
  
  # Gradient checkpointing
  gradient_checkpointing: true

# Polychromic-specific configuration
polychromic:
  # Diversity weight (Î» in loss function)
  diversity_weight: 0.3
  
  # Number of generations per batch for diversity computation
  n_generations: 3
  
  # Diversity metric
  diversity_metric: "semantic"  # Options: "semantic", "bleu", "distinct"
  
  # Generation parameters for diversity
  diversity_temperature: 0.9
  diversity_top_p: 0.9
  max_generation_length: 100
  
  # Diversity encoder
  diversity_encoder_model: "all-MiniLM-L6-v2"
  
  # Computational optimizations
  compute_diversity_every_n_steps: 1
  cache_diversity_encoder: true
  max_examples_for_diversity: 4

# Data - Phase 1 specific
data:
  # Phase 1 data (generated by split_training_phases.py)
  train_file: "data/processed/phases/training_data_phase1_sft.jsonl"
  
  max_length: 512
  seed: 42
  
  # Use standard train/eval split (90/10 of Phase 1 data)
  train_split: 0.9
  eval_split: 0.1
  
  # Qwen3 specific
  enable_thinking: false
  add_generation_prompt: false

# Evaluation Strategy
evaluation:
  strategy: "steps"
  eval_steps: 50
  logging_steps: 10
  save_steps: 50
  save_total_limit: 3
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 3
    threshold: 0.01
  
  # Best model selection
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false

# Output
output:
  output_dir: "./output/experiments/polychromic_warmstart"
  logging_dir: "./output/logs/polychromic_warmstart"
  save_safetensors: true
  save_only_model: false

# Weights & Biases
wandb:
  enabled: true
  project: "qwen3-twitter-lora"
  name: "polychromic-warmstart-phase1"
  tags:
    - "phase1"
    - "sft"
    - "warmstart"
    - "polychromic"
    - "diversity"
  notes: "Phase 1: Polychromic SFT warm-start with diversity regularization for GRPO refinement"
  
  # Logging
  log_model: true
  watch: "all"

# Reproducibility
reproducibility:
  seed: 42
  deterministic: false

# Overfitting Detection
overfitting_detection:
  max_train_eval_gap: 0.3
  min_eval_loss: 0.05
  max_eval_loss: 2.0

