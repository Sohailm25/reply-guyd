# Baseline LoRA - Phase 1 (SFT Warm-start)
#
# This config trains a baseline LoRA model on Phase 1 data (50% of full dataset)
# to create a warm-start checkpoint for subsequent GRPO training.
#
# Scientific rationale:
# - Shorter training (2 epochs vs 3) since Phase 2 continues from this checkpoint
# - Uses half the data (non-overlapping with Phase 2)
# - Establishes quality baseline before GRPO refinement
#
# Usage:
#   python scripts/training/train_model.py \
#     --config config/experiments/baseline_warmstart.yaml

_base_: ../lora_config.yaml

# Experiment metadata
experiment:
  name: "baseline_warmstart"
  phase: 1
  description: "Baseline LoRA warm-start for GRPO Phase 2"
  purpose: "Establish SFT baseline, prepare for GRPO refinement"

# Model (inherits from base)
model:
  # Same as base config

# LoRA (inherits from base)
lora:
  # Same as base config

# Training - adjusted for warm-start
training:
  # Shorter training since we continue in Phase 2
  num_epochs: 2  # vs 3 for full training
  
  # Standard hyperparameters
  learning_rate: 2.0e-4
  warmup_ratio: 0.03
  weight_decay: 0.01
  max_grad_norm: 1.0
  
  # Batch sizes (effective batch size = 16)
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 4
  
  # Optimizer
  optim: "adamw_torch"
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  
  # Learning rate scheduler
  lr_scheduler_type: "cosine"
  
  # Mixed precision
  bf16: true
  fp16: false
  
  # Gradient checkpointing
  gradient_checkpointing: true

# Data - Phase 1 specific
data:
  # Phase 1 data (generated by split_training_phases.py)
  train_file: "data/processed/phases/training_data_phase1_sft.jsonl"
  
  max_length: 512
  seed: 42
  
  # Use standard train/eval split (90/10 of Phase 1 data)
  train_split: 0.9
  eval_split: 0.1
  
  # Qwen3 specific
  enable_thinking: false
  add_generation_prompt: false

# Evaluation Strategy
evaluation:
  strategy: "steps"
  eval_steps: 50
  logging_steps: 10
  save_steps: 50
  save_total_limit: 3
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 3
    threshold: 0.01
  
  # Best model selection
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false

# Output
output:
  output_dir: "./output/experiments/baseline_warmstart"
  logging_dir: "./output/logs/baseline_warmstart"
  save_safetensors: true
  save_only_model: false

# Weights & Biases
wandb:
  enabled: true
  project: "qwen3-twitter-lora"
  name: "baseline-warmstart-phase1"
  tags:
    - "phase1"
    - "sft"
    - "warmstart"
    - "baseline"
  notes: "Phase 1: Baseline SFT warm-start for GRPO refinement"
  
  # Logging
  log_model: true
  watch: "all"

# Reproducibility
reproducibility:
  seed: 42
  deterministic: false

# Overfitting Detection
overfitting_detection:
  max_train_eval_gap: 0.3
  min_eval_loss: 0.05
  max_eval_loss: 2.0

